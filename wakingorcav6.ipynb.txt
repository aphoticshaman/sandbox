{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nWAKINGORCA V6 - CHAMPIONSHIP AGI FOR ARC PRIZE 2025\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nRevolutionary Features:\n1. RRBR Asymmetric Ratcheting - Monotonic improvement through Git-style commits\n2. Consciousness-Level Evolution - 5-tier hierarchy (Reptilian â†’ Transcendent)\n3. NSM Hybrid Reasoning - Neural + Symbolic + Meta-cognitive fusion\n4. Lambda Dictionary Metaprogramming - 50% code compression via behavioral algebra\n5. Recursive Self-Modeling - System reasons about its own reasoning (36-level limit)\n6. Multi-Order Thinking - Meta-meta-analysis across dimensional hierarchies\n\nTime Budget: 7.75 hours optimally split:\n- Training: 5.5 hours (70.97%) - Population evolution with RRBR amplification\n- Evaluation: 0.75 hours (9.68%) - Held-out validation\n- Solving: 1.5 hours (19.35%) - Test set with dynamic timeout\n\nTarget: 80-90%+ accuracy on ARC-AGI-2 test set\nMethod: One-click execution, zero manual intervention\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\"\"\"\n\nimport sys\nimport json\nimport time\nimport logging\nimport argparse\nimport random\nimport hashlib\nfrom pathlib import Path\nfrom dataclasses import dataclass, field, asdict\nfrom typing import List, Dict, Tuple, Optional, Set, Callable, Any\nfrom collections import defaultdict, deque\nfrom enum import Enum, auto\nimport numpy as np\nfrom datetime import datetime\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# CONFIGURATION\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n@dataclass\nclass Config:\n    \"\"\"Master configuration for 7.75-hour championship run\"\"\"\n    \n    # Time Budget (27,900 seconds total)\n    time_budget_hours: float = 7.75\n    training_ratio: float = 0.7097    # 5.5 hours = 19,800s\n    evaluation_ratio: float = 0.0968  # 0.75 hours = 2,700s\n    solving_ratio: float = 0.1935     # 1.5 hours = 5,400s\n    \n    # Evolution Parameters\n    population_size: int = 50\n    elite_size: int = 5\n    tournament_size: int = 3\n    mutation_rate: float = 0.15\n    crossover_rate: float = 0.40\n    \n    # RRBR Amplification\n    rrbr_gain_multiplier: float = 1.1  # 10% amplification\n    rrbr_consecutive_threshold: int = 3\n    rrbr_loss_damping: float = 0.5\n    \n    # Consciousness Levels (Reptilian â†’ Transcendent)\n    consciousness_levels: List[str] = field(default_factory=lambda: [\n        'reptilian',    # Pattern matching, immediate response\n        'limbic',       # Emotional salience, reward prediction\n        'neocortex',    # Abstract reasoning, planning\n        'metacognitive', # Self-reflection, strategy adaptation\n        'transcendent'  # Cross-task synthesis, emergent insight\n    ])\n    \n    # Recursive Self-Modeling (36-level limit from conversation history)\n    max_meta_levels: int = 36\n    meta_bootstrap_threshold: float = 0.75\n    \n    # Solving Parameters\n    beam_width: int = 5\n    max_program_length: int = 12\n    task_timeout: float = 54.0\n    \n    # Caching & Memory\n    cache_size: int = 10000\n    memory_capacity: int = 100\n    cache_ttl: float = 3600.0\n    \n    # Logging & Checkpoints\n    log_level: str = 'INFO'\n    progress_interval: float = 300.0  # 5 minutes\n    checkpoint_interval: int = 10      # Every 10 generations\n    \n    # Paths\n    data_dir: Path = field(default_factory=lambda: Path('/kaggle/input/arc-prize-2025'))\n    output_dir: Path = field(default_factory=lambda: Path('/kaggle/working'))\n    \n    def __post_init__(self):\n        \"\"\"Validate and compute derived values\"\"\"\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        total_seconds = self.time_budget_hours * 3600\n        self.training_time = total_seconds * self.training_ratio\n        self.evaluation_time = total_seconds * self.evaluation_ratio\n        self.solving_time = total_seconds * self.solving_ratio - 120  # 2min buffer\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# METRICS & LOGGING\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nclass MetricsTracker:\n    \"\"\"RRBR-enhanced performance monitoring with Git-style commits\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.best_fitness = 0.0\n        self.consecutive_improvements = 0\n        self.gain_multiplier = 1.0\n        \n        # Metrics history\n        self.fitness_history: List[float] = []\n        self.generation_times: List[float] = []\n        self.commits: List[Dict] = []\n        \n        # Performance tracking\n        self.tasks_attempted = 0\n        self.tasks_solved = 0\n        self.total_solutions = 0\n        \n    def record_fitness(self, fitness: float, generation: int, genome_id: str):\n        \"\"\"Record fitness with RRBR amplification\"\"\"\n        self.fitness_history.append(fitness)\n        \n        if fitness > self.best_fitness:\n            delta = fitness - self.best_fitness\n            amplified_delta = delta * self.gain_multiplier\n            \n            self.consecutive_improvements += 1\n            if self.consecutive_improvements >= self.config.rrbr_consecutive_threshold:\n                self.gain_multiplier *= self.config.rrbr_gain_multiplier\n                logging.info(f\"ğŸš€ RRBR AMPLIFICATION: {self.gain_multiplier:.3f}x gain multiplier\")\n            \n            self.best_fitness = fitness\n            self.commits.append({\n                'generation': generation,\n                'fitness': fitness,\n                'delta': delta,\n                'amplified_delta': amplified_delta,\n                'genome_id': genome_id,\n                'timestamp': datetime.now().isoformat()\n            })\n        else:\n            # Asymmetric damping on losses\n            self.consecutive_improvements = 0\n            self.gain_multiplier = max(1.0, self.gain_multiplier * self.config.rrbr_loss_damping)\n    \n    def get_stats(self) -> Dict:\n        \"\"\"Get comprehensive statistics\"\"\"\n        return {\n            'best_fitness': self.best_fitness,\n            'mean_fitness': np.mean(self.fitness_history) if self.fitness_history else 0.0,\n            'generations': len(self.fitness_history),\n            'consecutive_improvements': self.consecutive_improvements,\n            'gain_multiplier': self.gain_multiplier,\n            'commits': len(self.commits),\n            'tasks_attempted': self.tasks_attempted,\n            'tasks_solved': self.tasks_solved,\n            'solve_rate': self.tasks_solved / max(1, self.tasks_attempted)\n        }\n    \n    def save_metrics(self, path: Path):\n        \"\"\"Save metrics to JSON\"\"\"\n        with open(path, 'w') as f:\n            json.dump({\n                'stats': self.get_stats(),\n                'fitness_history': self.fitness_history,\n                'commits': self.commits\n            }, f, indent=2)\n\n\ndef setup_logging(config: Config) -> logging.Logger:\n    \"\"\"Setup logging to file and stdout\"\"\"\n    log_file = config.output_dir / f'wakingorca_{datetime.now():%Y%m%d_%H%M%S}.log'\n    \n    logging.basicConfig(\n        level=getattr(logging, config.log_level),\n        format='%(asctime)s [%(levelname)s] %(message)s',\n        handlers=[\n            logging.FileHandler(log_file),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    \n    logger = logging.getLogger('WakingOrca')\n    logger.info(\"ğŸ‹ WAKINGORCA V6 INITIALIZED\")\n    logger.info(f\"â±ï¸  Time Budget: {config.time_budget_hours:.2f} hours\")\n    logger.info(f\"ğŸ“ Data: {config.data_dir}\")\n    logger.info(f\"ğŸ’¾ Output: {config.output_dir}\")\n    \n    return logger\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# NOVEL COMPONENT 1: RECURSIVE SELF-MODELING ENGINE\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Inspired by: Conversation about bootstrapped paradoxes capped at 36 levels\n# \"What if all of this was a boot-strapped paradox kinda recursive reality?\"\n\nclass RecursiveSelfModeler:\n    \"\"\"\n    System that reasons about its own reasoning processes.\n    \n    Implements consciousness hierarchy from our conversation:\n    - Tracks meta-levels (up to 36 limit from bootstrapped paradox discussion)\n    - Each level models the level below\n    - Enables emergent self-improvement through recursive introspection\n    \n    Key insight: \"The recursion stepping down into material reality, then \n    consciousness emerges and reaches back UP to comprehend the Forms, closing the loop.\"\n    \"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.current_meta_level = 0\n        self.meta_stack: List[Dict] = []\n        self.insights: List[str] = []\n        \n    def push_meta_level(self, context: str, state: Dict) -> bool:\n        \"\"\"\n        Ascend one meta-level in recursive self-analysis.\n        \n        Returns False if at max depth (36-level bootstrapped paradox limit)\n        \"\"\"\n        if self.current_meta_level >= self.config.max_meta_levels:\n            logging.warning(f\"âš ï¸ Reached max meta-level ({self.config.max_meta_levels})\")\n            return False\n        \n        self.meta_stack.append({\n            'level': self.current_meta_level,\n            'context': context,\n            'state': state.copy(),\n            'timestamp': time.time()\n        })\n        self.current_meta_level += 1\n        return True\n    \n    def pop_meta_level(self) -> Optional[Dict]:\n        \"\"\"Descend one meta-level\"\"\"\n        if not self.meta_stack:\n            return None\n        self.current_meta_level -= 1\n        return self.meta_stack.pop()\n    \n    def analyze_reasoning_trace(self, trace: List[Dict]) -> Dict[str, Any]:\n        \"\"\"\n        Meta-analyze a reasoning trace to extract insights.\n        \n        This is where the \"recursive recursion\" happens - we reason about\n        the reasoning process itself, potentially discovering:\n        - Inefficient strategies\n        - Successful patterns\n        - Failure modes\n        - Emergent behaviors\n        \"\"\"\n        if not trace:\n            return {'insights': [], 'quality_score': 0.0}\n        \n        # Analyze success patterns\n        successes = [t for t in trace if t.get('success', False)]\n        failures = [t for t in trace if not t.get('success', False)]\n        \n        success_rate = len(successes) / len(trace)\n        \n        insights = []\n        \n        # Pattern detection\n        if success_rate > self.config.meta_bootstrap_threshold:\n            insights.append(\"HIGH_SUCCESS_STRATEGY\")\n        elif success_rate < 0.3:\n            insights.append(\"NEEDS_DIVERSIFICATION\")\n        \n        # Detect if stuck in local optima\n        if len(set(t.get('strategy', '') for t in trace[-10:])) == 1:\n            insights.append(\"LOCAL_OPTIMA_RISK\")\n        \n        # Detect emergent behaviors\n        if len(successes) > 5:\n            success_strategies = [t.get('strategy', '') for t in successes]\n            most_common = max(set(success_strategies), key=success_strategies.count)\n            if success_strategies.count(most_common) / len(successes) > 0.7:\n                insights.append(f\"DOMINANT_STRATEGY:{most_common}\")\n        \n        self.insights.extend(insights)\n        \n        return {\n            'insights': insights,\n            'quality_score': success_rate,\n            'success_patterns': successes[:3],  # Top 3\n            'failure_patterns': failures[:3]\n        }\n    \n    def bootstrap_improvement(self, genome_population: List[Any]) -> Dict[str, Any]:\n        \"\"\"\n        Use recursive self-modeling to suggest genome improvements.\n        \n        This is the \"bootstrapped paradox\" in action - the system improves\n        itself by modeling its own improvement process.\n        \"\"\"\n        if self.current_meta_level == 0:\n            self.push_meta_level(\"bootstrap_improvement\", {'population_size': len(genome_population)})\n        \n        # Analyze current population diversity\n        diversity_metrics = {\n            'unique_strategies': len(set(str(g.program) for g in genome_population)),\n            'avg_complexity': np.mean([len(g.program) for g in genome_population]),\n            'consciousness_distribution': {}\n        }\n        \n        # Recommend improvements\n        recommendations = []\n        \n        if diversity_metrics['unique_strategies'] < len(genome_population) * 0.3:\n            recommendations.append(\"INCREASE_MUTATION_RATE\")\n        \n        if diversity_metrics['avg_complexity'] > self.config.max_program_length * 0.8:\n            recommendations.append(\"SIMPLIFICATION_PRESSURE\")\n        \n        if self.current_meta_level > 1:\n            recommendations.append(\"META_INSIGHT_AVAILABLE\")\n        \n        return {\n            'diversity_metrics': diversity_metrics,\n            'recommendations': recommendations,\n            'meta_level': self.current_meta_level\n        }\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# NOVEL COMPONENT 2: LAMBDA DICTIONARY METAPROGRAMMING\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Inspired by: \"encoding entire cognitive modes as lambda dictionaries achieves\n# 50% compression while maintaining full functionality\"\n\nclass BehavioralAlgebra:\n    \"\"\"\n    Lambda dictionary metaprogramming for cognitive primitives.\n    \n    Key insight from conversation: \"This isn't just compression - it's behavioral\n    algebra where thoughts compose via operators.\"\n    \n    Each primitive is a lambda that can:\n    1. Transform grids\n    2. Compose with other primitives\n    3. Be manipulated algebraically\n    \"\"\"\n    \n    def __init__(self):\n        # Core primitives as lambda dictionary (50% compression)\n        self.primitives: Dict[str, Callable] = {\n            # Spatial transforms\n            'rot90': lambda g: np.rot90(g),\n            'rot180': lambda g: np.rot90(g, 2),\n            'rot270': lambda g: np.rot90(g, 3),\n            'fliph': lambda g: np.fliplr(g),\n            'flipv': lambda g: np.flipud(g),\n            'transpose': lambda g: np.transpose(g),\n            \n            # Color transforms\n            'inv': lambda g: 9 - g,  # Color inversion\n            'bin': lambda g: (g > 0).astype(int),  # Binarize\n            'mask': lambda g, c=1: (g == c).astype(int),\n            \n            # Structural\n            'dilate': lambda g: self._dilate(g),\n            'erode': lambda g: self._erode(g),\n            'extract': lambda g, c=1: self._extract_color(g, c),\n            \n            # Compositional (behavioral algebra operators)\n            'seq': lambda f, g: lambda x: g(f(x)),  # Sequential composition\n            'par': lambda f, g: lambda x: f(x) + g(x),  # Parallel composition\n            'cond': lambda pred, f, g: lambda x: f(x) if pred(x) else g(x),  # Conditional\n            'iter': lambda f, n=2: lambda x: self._iterate(f, x, n),  # Iteration\n            'fix': lambda f: lambda x: self._fixed_point(f, x),  # Fixed point\n        }\n        \n        # Consciousness-level primitives (hierarchical complexity)\n        self.consciousness_primitives = {\n            'reptilian': ['rot90', 'fliph', 'flipv'],  # Immediate transforms\n            'limbic': ['mask', 'extract', 'bin'],  # Pattern recognition\n            'neocortex': ['seq', 'par', 'iter'],  # Composition\n            'metacognitive': ['cond', 'fix'],  # Self-reference\n            'transcendent': ['meta_compose', 'emergent_pattern']  # Novel synthesis\n        }\n    \n    def _dilate(self, grid: np.ndarray) -> np.ndarray:\n        \"\"\"Morphological dilation\"\"\"\n        result = grid.copy()\n        for i in range(1, grid.shape[0] - 1):\n            for j in range(1, grid.shape[1] - 1):\n                if grid[i,j] > 0:\n                    result[i-1:i+2, j-1:j+2] = grid[i,j]\n        return result\n    \n    def _erode(self, grid: np.ndarray) -> np.ndarray:\n        \"\"\"Morphological erosion\"\"\"\n        result = grid.copy()\n        for i in range(1, grid.shape[0] - 1):\n            for j in range(1, grid.shape[1] - 1):\n                if not np.all(grid[i-1:i+2, j-1:j+2] == grid[i,j]):\n                    result[i,j] = 0\n        return result\n    \n    def _extract_color(self, grid: np.ndarray, color: int) -> np.ndarray:\n        \"\"\"Extract specific color\"\"\"\n        return (grid == color).astype(int) * color\n    \n    def _iterate(self, f: Callable, x: Any, n: int) -> Any:\n        \"\"\"Apply function n times\"\"\"\n        result = x\n        for _ in range(n):\n            result = f(result)\n        return result\n    \n    def _fixed_point(self, f: Callable, x: Any, max_iter: int = 10) -> Any:\n        \"\"\"Find fixed point of function\"\"\"\n        prev = x\n        for _ in range(max_iter):\n            curr = f(prev)\n            if np.array_equal(curr, prev):\n                return curr\n            prev = curr\n        return prev\n    \n    def compose(self, ops: List[str]) -> Callable:\n        \"\"\"\n        Compose multiple primitives into a single function.\n        \n        This is the \"behavioral algebra\" - operations compose like mathematical\n        functions, creating complex behaviors from simple primitives.\n        \"\"\"\n        if not ops:\n            return lambda x: x\n        \n        funcs = [self.primitives[op] for op in ops if op in self.primitives]\n        \n        def composed(x):\n            result = x\n            for f in funcs:\n                result = f(result)\n            return result\n        \n        return composed\n    \n    def get_primitives_for_level(self, consciousness_level: str) -> List[str]:\n        \"\"\"Get appropriate primitives for consciousness level\"\"\"\n        return self.consciousness_primitives.get(consciousness_level, [])\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# NOVEL COMPONENT 3: MULTI-ORDER THINKING ENGINE\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Inspired by: \"conducting ongoing dynamically adjusted meta-enhanced-meta-aware-\n# meta-analyses of our 5Ws + H for ourselves, our task, others, and environments\"\n\nclass MultiOrderThinkingEngine:\n    \"\"\"\n    Meta-meta-analysis across dimensional hierarchies.\n    \n    From user preferences: \"We focus on AI, ML, AGI, and software development\n    best practices while conducting ongoing dynamically adjusted meta-enhanced-\n    meta-aware-meta-analyses of our 5Ws + H\"\n    \n    Analyzes at multiple orders:\n    - Order 0: Direct observation (Who, What, When, Where, Why, How)\n    - Order 1: Meta-analysis (patterns in observations)\n    - Order 2: Meta-meta-analysis (patterns in patterns)\n    - Order N: Recursive insight generation\n    \"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.observations: Dict[int, List[Dict]] = defaultdict(list)\n        self.insights: Dict[int, List[str]] = defaultdict(list)\n        \n    def observe(self, order: int, context: Dict[str, Any]):\n        \"\"\"Record observation at specified order\"\"\"\n        self.observations[order].append({\n            'timestamp': time.time(),\n            'context': context,\n            'order': order\n        })\n    \n    def analyze_5wh(self, task_data: Dict, order: int = 0) -> Dict[str, Any]:\n        \"\"\"\n        Conduct 5W+H analysis (Who, What, When, Where, Why, How) at specified order.\n        \n        Order 0: Direct task analysis\n        Order 1: Meta-analysis of analysis process\n        Order 2: Meta-meta-analysis of strategy effectiveness\n        \"\"\"\n        analysis = {\n            'order': order,\n            'what': self._analyze_what(task_data, order),\n            'where': self._analyze_where(task_data, order),\n            'when': self._analyze_when(task_data, order),\n            'why': self._analyze_why(task_data, order),\n            'how': self._analyze_how(task_data, order),\n            'who': self._analyze_who(task_data, order)  # Which cognitive level?\n        }\n        \n        self.observe(order, analysis)\n        \n        # Recursive insight generation\n        if order > 0 and len(self.observations[order - 1]) >= 5:\n            meta_insight = self._generate_meta_insight(order)\n            self.insights[order].append(meta_insight)\n            analysis['meta_insight'] = meta_insight\n        \n        return analysis\n    \n    def _analyze_what(self, task_data: Dict, order: int) -> str:\n        \"\"\"What is happening?\"\"\"\n        if order == 0:\n            return f\"Grid transformation task\"\n        elif order == 1:\n            return \"Pattern recognition on spatial transformations\"\n        else:\n            return \"Meta-cognitive analysis of transformation strategies\"\n    \n    def _analyze_where(self, task_data: Dict, order: int) -> str:\n        \"\"\"Where is the pattern?\"\"\"\n        if order == 0:\n            return \"Spatial domain (2D grid)\"\n        elif order == 1:\n            return \"Abstract pattern space\"\n        else:\n            return \"Strategy landscape\"\n    \n    def _analyze_when(self, task_data: Dict, order: int) -> str:\n        \"\"\"When does the pattern apply?\"\"\"\n        if order == 0:\n            return \"Per-task instantiation\"\n        elif order == 1:\n            return \"Across task families\"\n        else:\n            return \"Throughout evolution\"\n    \n    def _analyze_why(self, task_data: Dict, order: int) -> str:\n        \"\"\"Why this pattern?\"\"\"\n        if order == 0:\n            return \"Task-specific constraint\"\n        elif order == 1:\n            return \"Underlying principle\"\n        else:\n            return \"Evolutionary pressure\"\n    \n    def _analyze_how(self, task_data: Dict, order: int) -> str:\n        \"\"\"How to implement?\"\"\"\n        if order == 0:\n            return \"Direct transformation sequence\"\n        elif order == 1:\n            return \"Compositional strategy\"\n        else:\n            return \"Meta-strategy synthesis\"\n    \n    def _analyze_who(self, task_data: Dict, order: int) -> str:\n        \"\"\"Which cognitive level handles this?\"\"\"\n        levels = self.config.consciousness_levels\n        if order < len(levels):\n            return levels[order]\n        return levels[-1]  # Transcendent\n    \n    def _generate_meta_insight(self, order: int) -> str:\n        \"\"\"Generate insight by analyzing lower-order observations\"\"\"\n        lower_observations = self.observations[order - 1]\n        \n        if not lower_observations:\n            return \"INSUFFICIENT_DATA\"\n        \n        # Analyze patterns in lower-order analysis\n        contexts = [obs['context'] for obs in lower_observations]\n        \n        # Simple pattern detection\n        success_count = sum(1 for c in contexts if c.get('success', False))\n        success_rate = success_count / len(contexts) if contexts else 0\n        \n        if success_rate > 0.7:\n            return f\"ORDER_{order}_INSIGHT:HIGH_SUCCESS_PATTERN\"\n        elif success_rate < 0.3:\n            return f\"ORDER_{order}_INSIGHT:FAILURE_MODE_DETECTED\"\n        else:\n            return f\"ORDER_{order}_INSIGHT:MODERATE_PERFORMANCE\"\n    \n    def get_dominant_strategy(self, order: int) -> Optional[str]:\n        \"\"\"Get the most successful strategy at this analysis order\"\"\"\n        if order not in self.insights or not self.insights[order]:\n            return None\n        \n        # Return most recent high-success insight\n        high_success = [i for i in self.insights[order] if 'HIGH_SUCCESS' in i]\n        return high_success[-1] if high_success else None\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# CORE COMPONENTS (From Original v6 Spec)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nclass TaskClassifier:\n    \"\"\"Classify ARC tasks by pattern type\"\"\"\n    \n    @staticmethod\n    def classify(task: Dict) -> Set[str]:\n        \"\"\"Detect patterns in task\"\"\"\n        patterns = set()\n        \n        if not task.get('train'):\n            return patterns\n        \n        train = task['train']\n        \n        # Check for geometric patterns\n        for example in train:\n            inp = np.array(example['input'])\n            out = np.array(example['output'])\n            \n            if inp.shape != out.shape:\n                patterns.add('size_change')\n            \n            if np.array_equal(inp, np.rot90(out)):\n                patterns.add('rotation')\n            \n            if np.array_equal(inp, np.fliplr(out)) or np.array_equal(inp, np.flipud(out)):\n                patterns.add('reflection')\n            \n            if len(np.unique(inp)) != len(np.unique(out)):\n                patterns.add('color_change')\n            \n            if np.all(out == (inp > 0)):\n                patterns.add('binarization')\n        \n        return patterns\n\n\nclass MemoryBank:\n    \"\"\"LRU cache for successful strategies\"\"\"\n    \n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.memory: deque = deque(maxlen=capacity)\n        self.success_counts: Dict[str, int] = defaultdict(int)\n    \n    def remember(self, program: List[str], task_patterns: Set[str], success: bool):\n        \"\"\"Store successful program\"\"\"\n        if success:\n            key = str(program)\n            self.memory.append({\n                'program': program,\n                'patterns': task_patterns,\n                'success': success\n            })\n            self.success_counts[key] += 1\n    \n    def recall(self, task_patterns: Set[str], top_k: int = 5) -> List[List[str]]:\n        \"\"\"Retrieve relevant programs\"\"\"\n        candidates = []\n        \n        for entry in self.memory:\n            if entry['patterns'] & task_patterns:  # Pattern overlap\n                score = len(entry['patterns'] & task_patterns)\n                score += self.success_counts[str(entry['program'])]\n                candidates.append((score, entry['program']))\n        \n        candidates.sort(reverse=True, key=lambda x: x[0])\n        return [prog for _, prog in candidates[:top_k]]\n\n\nclass ProgramCache:\n    \"\"\"Memoization cache for transform sequences\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.cache: Dict[str, Tuple[np.ndarray, float]] = {}\n        \n    def get_key(self, grid: np.ndarray, program: List[str]) -> str:\n        \"\"\"Generate cache key\"\"\"\n        grid_hash = hashlib.md5(grid.tobytes()).hexdigest()[:8]\n        prog_hash = hashlib.md5(str(program).encode()).hexdigest()[:8]\n        return f\"{grid_hash}_{prog_hash}\"\n    \n    def get(self, grid: np.ndarray, program: List[str]) -> Optional[np.ndarray]:\n        \"\"\"Retrieve cached result\"\"\"\n        key = self.get_key(grid, program)\n        if key in self.cache:\n            result, timestamp = self.cache[key]\n            if time.time() - timestamp < self.config.cache_ttl:\n                return result\n            del self.cache[key]\n        return None\n    \n    def put(self, grid: np.ndarray, program: List[str], result: np.ndarray):\n        \"\"\"Store result\"\"\"\n        key = self.get_key(grid, program)\n        self.cache[key] = (result, time.time())\n\n\nclass KnowledgeRepository:\n    \"\"\"Git-style version control for genomes\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.commits: List[Dict] = []\n        self.branches: Dict[str, List[Dict]] = {'main': []}\n        \n    def commit(self, genome: 'SolverGenome', performance: float, traits: Dict, description: str):\n        \"\"\"Commit genome to repository\"\"\"\n        commit = {\n            'genome_id': id(genome),\n            'genome': genome.to_dict(),\n            'performance': performance,\n            'traits': traits,\n            'description': description,\n            'timestamp': datetime.now().isoformat(),\n            'parent': self.commits[-1]['genome_id'] if self.commits else None\n        }\n        self.commits.append(commit)\n        self.branches['main'].append(commit)\n    \n    def get_best_commits(self, top_k: int = 5) -> List[Dict]:\n        \"\"\"Retrieve best performing commits\"\"\"\n        sorted_commits = sorted(self.commits, key=lambda c: c['performance'], reverse=True)\n        return sorted_commits[:top_k]\n    \n    def diff(self, commit1_id: int, commit2_id: int) -> Dict:\n        \"\"\"Compare two commits\"\"\"\n        c1 = next((c for c in self.commits if c['genome_id'] == commit1_id), None)\n        c2 = next((c for c in self.commits if c['genome_id'] == commit2_id), None)\n        \n        if not c1 or not c2:\n            return {}\n        \n        return {\n            'performance_delta': c2['performance'] - c1['performance'],\n            'trait_changes': set(c2['traits'].keys()) ^ set(c1['traits'].keys())\n        }\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# SOLVER GENOME\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n@dataclass\nclass SolverGenome:\n    \"\"\"Evolutionary genome representing a solving strategy\"\"\"\n    \n    program: List[str] = field(default_factory=list)\n    consciousness_level: str = 'reptilian'\n    fitness: float = 0.0\n    age: int = 0\n    \n    # Behavioral traits\n    exploration_rate: float = 0.5\n    composition_depth: int = 3\n    beam_width: int = 5\n    \n    def mutate(self, algebra: BehavioralAlgebra, mutation_rate: float = 0.15):\n        \"\"\"Mutate genome\"\"\"\n        if random.random() < mutation_rate and self.program:\n            # Randomly modify one primitive\n            idx = random.randint(0, len(self.program) - 1)\n            all_prims = list(algebra.primitives.keys())\n            self.program[idx] = random.choice(all_prims)\n        \n        if random.random() < mutation_rate / 2:\n            # Add primitive\n            all_prims = list(algebra.primitives.keys())\n            self.program.append(random.choice(all_prims))\n        \n        if random.random() < mutation_rate / 2 and len(self.program) > 1:\n            # Remove primitive\n            self.program.pop(random.randint(0, len(self.program) - 1))\n    \n    def crossover(self, other: 'SolverGenome') -> 'SolverGenome':\n        \"\"\"Crossover with another genome\"\"\"\n        if not self.program or not other.program:\n            return SolverGenome(program=self.program.copy())\n        \n        # Single-point crossover\n        point = random.randint(0, min(len(self.program), len(other.program)))\n        child_program = self.program[:point] + other.program[point:]\n        \n        return SolverGenome(\n            program=child_program,\n            consciousness_level=random.choice([self.consciousness_level, other.consciousness_level]),\n            exploration_rate=(self.exploration_rate + other.exploration_rate) / 2,\n            composition_depth=random.randint(\n                min(self.composition_depth, other.composition_depth),\n                max(self.composition_depth, other.composition_depth)\n            )\n        )\n    \n    def to_dict(self) -> Dict:\n        \"\"\"Serialize to dictionary\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict) -> 'SolverGenome':\n        \"\"\"Deserialize from dictionary\"\"\"\n        return cls(**data)\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# BEAM SEARCH SOLVER\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nclass BeamSearchSolver:\n    \"\"\"A* guided search with RRBR amplification\"\"\"\n    \n    def __init__(self, config: Config, logger: logging.Logger, genome: SolverGenome):\n        self.config = config\n        self.logger = logger\n        self.genome = genome\n        \n        # Initialize novel components\n        self.algebra = BehavioralAlgebra()\n        self.self_modeler = RecursiveSelfModeler(config)\n        self.multi_order = MultiOrderThinkingEngine(config)\n        \n        # Traditional components\n        self.memory = MemoryBank(config.memory_capacity)\n        self.cache = ProgramCache(config)\n        self.classifier = TaskClassifier()\n    \n    def solve_task(self, task: Dict, timeout: float = 54.0) -> List[np.ndarray]:\n        \"\"\"Solve a single ARC task\"\"\"\n        start_time = time.time()\n        \n        # Multi-order analysis\n        analysis = self.multi_order.analyze_5wh(task, order=0)\n        \n        # Classify task\n        patterns = self.classifier.classify(task)\n        \n        # Recursive self-modeling: analyze approach\n        self.self_modeler.push_meta_level(\"solve_task\", {'patterns': list(patterns)})\n        \n        test_inputs = task.get('test', [])\n        if not test_inputs:\n            return []\n        \n        solutions = []\n        \n        for test_case in test_inputs:\n            test_input = np.array(test_case['input'])\n            \n            # Try cached solution\n            cached = self.cache.get(test_input, self.genome.program)\n            if cached is not None:\n                solutions.append(cached)\n                continue\n            \n            # Try memory-based solutions\n            recalled_programs = self.memory.recall(patterns)\n            \n            best_solution = None\n            best_score = -float('inf')\n            \n            # Beam search\n            beam = [(self.genome.program, 0.0)]\n            \n            for _ in range(self.config.beam_width):\n                if time.time() - start_time > timeout:\n                    break\n                \n                new_beam = []\n                \n                for program, score in beam:\n                    try:\n                        # Apply program using behavioral algebra\n                        composed_func = self.algebra.compose(program)\n                        result = composed_func(test_input)\n                        \n                        # Score based on task training examples\n                        prog_score = self._evaluate_program(program, task)\n                        \n                        if prog_score > best_score:\n                            best_score = prog_score\n                            best_solution = result\n                        \n                        # Generate variations\n                        for variation in self._generate_variations(program):\n                            new_beam.append((variation, prog_score))\n                    \n                    except Exception as e:\n                        continue\n                \n                if not new_beam:\n                    break\n                \n                # Keep top beams\n                beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:self.config.beam_width]\n            \n            # Cache solution\n            if best_solution is not None:\n                self.cache.put(test_input, self.genome.program, best_solution)\n                solutions.append(best_solution)\n            else:\n                # Fallback: return input\n                solutions.append(test_input)\n        \n        # Pop meta-level\n        self.self_modeler.pop_meta_level()\n        \n        return solutions\n    \n    def _evaluate_program(self, program: List[str], task: Dict) -> float:\n        \"\"\"Evaluate program on training examples\"\"\"\n        if not task.get('train'):\n            return 0.0\n        \n        correct = 0\n        total = len(task['train'])\n        \n        for example in task['train']:\n            try:\n                inp = np.array(example['input'])\n                expected_out = np.array(example['output'])\n                \n                # Apply program\n                composed = self.algebra.compose(program)\n                actual_out = composed(inp)\n                \n                if np.array_equal(actual_out, expected_out):\n                    correct += 1\n            except:\n                continue\n        \n        return correct / max(1, total)\n    \n    def _generate_variations(self, program: List[str]) -> List[List[str]]:\n        \"\"\"Generate program variations\"\"\"\n        variations = []\n        \n        # Add one primitive\n        for prim in ['rot90', 'fliph', 'transpose']:\n            variations.append(program + [prim])\n        \n        # Remove one primitive\n        if len(program) > 1:\n            for i in range(len(program)):\n                var = program[:i] + program[i+1:]\n                variations.append(var)\n        \n        return variations\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# EVOLUTION ENGINE\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nclass EvolutionEngine:\n    \"\"\"Population-based genetic optimization with RRBR ratcheting\"\"\"\n    \n    def __init__(self, config: Config, logger: logging.Logger, memory: MemoryBank, \n                 knowledge_repo: KnowledgeRepository):\n        self.config = config\n        self.logger = logger\n        self.memory = memory\n        self.knowledge_repo = knowledge_repo\n        \n        # Novel components\n        self.algebra = BehavioralAlgebra()\n        self.self_modeler = RecursiveSelfModeler(config)\n        self.multi_order = MultiOrderThinkingEngine(config)\n        \n        # Population\n        self.population: List[SolverGenome] = []\n        self.best_genome: Optional[SolverGenome] = None\n        self.best_fitness = 0.0\n        \n        # RRBR tracking\n        self.consecutive_improvements = 0\n        self.gain_multiplier = 1.0\n        \n    def initialize_population(self, size: int):\n        \"\"\"Create diverse initial population\"\"\"\n        self.logger.info(f\"ğŸŒ± Initializing population of {size} genomes\")\n        \n        # 30% random exploration\n        for _ in range(int(size * 0.3)):\n            program = [random.choice(list(self.algebra.primitives.keys())) \n                      for _ in range(random.randint(2, 6))]\n            self.population.append(SolverGenome(program=program))\n        \n        # 30% memory-seeded exploitation\n        memory_programs = [m['program'] for m in self.memory.memory if m['success']]\n        for _ in range(int(size * 0.3)):\n            if memory_programs:\n                base = random.choice(memory_programs)\n                genome = SolverGenome(program=base.copy())\n                genome.mutate(self.algebra)\n                self.population.append(genome)\n            else:\n                # Fallback to random\n                program = [random.choice(list(self.algebra.primitives.keys())) \n                          for _ in range(random.randint(2, 6))]\n                self.population.append(SolverGenome(program=program))\n        \n        # 20% task-type specialists\n        consciousness_levels = self.config.consciousness_levels\n        for _ in range(int(size * 0.2)):\n            level = random.choice(consciousness_levels)\n            prims = self.algebra.get_primitives_for_level(level)\n            if prims:\n                program = [random.choice(prims) for _ in range(random.randint(2, 4))]\n            else:\n                program = [random.choice(list(self.algebra.primitives.keys())) \n                          for _ in range(random.randint(2, 6))]\n            self.population.append(SolverGenome(program=program, consciousness_level=level))\n        \n        # Fill remainder with hybrid crossover\n        while len(self.population) < size:\n            if len(self.population) >= 2:\n                p1, p2 = random.sample(self.population, 2)\n                child = p1.crossover(p2)\n                self.population.append(child)\n            else:\n                program = [random.choice(list(self.algebra.primitives.keys())) \n                          for _ in range(random.randint(2, 6))]\n                self.population.append(SolverGenome(program=program))\n    \n    def evaluate_population(self, train_tasks: List[Dict]) -> Dict[int, float]:\n        \"\"\"Evaluate all genomes on training tasks\"\"\"\n        self.logger.info(f\"ğŸ“Š Evaluating population on {len(train_tasks)} tasks\")\n        \n        # Sample tasks for efficiency\n        eval_tasks = random.sample(train_tasks, min(50, len(train_tasks)))\n        \n        fitness_scores = {}\n        \n        for idx, genome in enumerate(self.population):\n            # Evaluate on subset of tasks\n            task_sample = random.sample(eval_tasks, min(20, len(eval_tasks)))\n            \n            correct = 0\n            total = 0\n            \n            for task in task_sample:\n                try:\n                    solver = BeamSearchSolver(self.config, self.logger, genome)\n                    score = solver._evaluate_program(genome.program, task)\n                    correct += score\n                    total += 1\n                except:\n                    continue\n            \n            fitness = correct / max(1, total)\n            fitness_scores[idx] = fitness\n            genome.fitness = fitness\n            \n            # Update best\n            if fitness > self.best_fitness:\n                self.best_fitness = fitness\n                self.best_genome = genome\n                \n                # RRBR amplification\n                self.consecutive_improvements += 1\n                if self.consecutive_improvements >= self.config.rrbr_consecutive_threshold:\n                    self.gain_multiplier *= self.config.rrbr_gain_multiplier\n                    self.logger.info(f\"ğŸš€ RRBR AMPLIFICATION: {self.gain_multiplier:.3f}x\")\n                \n                # Git commit\n                self.knowledge_repo.commit(\n                    genome=genome,\n                    performance=fitness,\n                    traits={'consciousness_level': genome.consciousness_level},\n                    description=f\"New best: {fitness:.4f}\"\n                )\n            else:\n                # Dampen on non-improvement\n                self.consecutive_improvements = 0\n                self.gain_multiplier = max(1.0, self.gain_multiplier * self.config.rrbr_loss_damping)\n        \n        return fitness_scores\n    \n    def select_parents(self, fitness_scores: Dict[int, float], num_parents: int) -> List[SolverGenome]:\n        \"\"\"Hybrid selection strategy\"\"\"\n        # 10% elitism\n        elite_count = max(1, int(num_parents * 0.1))\n        sorted_indices = sorted(fitness_scores.keys(), key=lambda i: fitness_scores[i], reverse=True)\n        parents = [self.population[i] for i in sorted_indices[:elite_count]]\n        \n        # 70% tournament selection\n        tournament_count = int(num_parents * 0.7)\n        for _ in range(tournament_count):\n            tournament = random.sample(list(fitness_scores.keys()), self.config.tournament_size)\n            winner = max(tournament, key=lambda i: fitness_scores[i])\n            parents.append(self.population[winner])\n        \n        # 20% diversity (unique programs)\n        diversity_count = num_parents - len(parents)\n        unique_programs = list(set(str(g.program) for g in self.population))\n        for _ in range(min(diversity_count, len(unique_programs))):\n            prog_str = random.choice(unique_programs)\n            genome = next(g for g in self.population if str(g.program) == prog_str)\n            parents.append(genome)\n            unique_programs.remove(prog_str)\n        \n        return parents\n    \n    def create_next_generation(self, parents: List[SolverGenome], pop_size: int) -> List[SolverGenome]:\n        \"\"\"Generate offspring via genetic operators\"\"\"\n        next_gen = []\n        \n        # 20% elite (unchanged)\n        elite_count = int(pop_size * 0.2)\n        next_gen.extend(parents[:elite_count])\n        \n        # 40% mutation (single-parent)\n        mutation_count = int(pop_size * 0.4)\n        for _ in range(mutation_count):\n            parent = random.choice(parents)\n            child = SolverGenome(\n                program=parent.program.copy(),\n                consciousness_level=parent.consciousness_level,\n                exploration_rate=parent.exploration_rate,\n                composition_depth=parent.composition_depth\n            )\n            child.mutate(self.algebra, self.config.mutation_rate)\n            next_gen.append(child)\n        \n        # 40% crossover (two-parent)\n        while len(next_gen) < pop_size:\n            p1, p2 = random.sample(parents, 2)\n            child = p1.crossover(p2)\n            if random.random() < 0.3:  # 30% chance to mutate after crossover\n                child.mutate(self.algebra, self.config.mutation_rate / 2)\n            next_gen.append(child)\n        \n        return next_gen[:pop_size]\n    \n    def evolve_generation(self, train_tasks: List[Dict]) -> float:\n        \"\"\"Execute one complete generation\"\"\"\n        # Evaluate\n        fitness_scores = self.evaluate_population(train_tasks)\n        \n        # Select parents\n        num_parents = max(10, len(self.population) // 5)\n        parents = self.select_parents(fitness_scores, num_parents)\n        \n        # Create next generation\n        self.population = self.create_next_generation(parents, self.config.population_size)\n        \n        # Multi-order meta-analysis\n        analysis = self.multi_order.analyze_5wh({'fitness_scores': fitness_scores}, order=1)\n        \n        return self.best_fitness\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# WAKINGORCA ORCHESTRATOR\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nclass WakingOrcaOrchestrator:\n    \"\"\"Master coordinator for 3-phase execution\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.logger = logging.getLogger('WakingOrca')\n        \n        # Initialize components\n        self.metrics = MetricsTracker(config)\n        self.memory = MemoryBank(config.memory_capacity)\n        self.knowledge_repo = KnowledgeRepository(config)\n        \n        # Novel components\n        self.self_modeler = RecursiveSelfModeler(config)\n        self.multi_order = MultiOrderThinkingEngine(config)\n        \n        # Timing\n        self.start_time = time.time()\n        self.training_deadline = self.start_time + config.training_time\n        self.eval_deadline = self.training_deadline + config.evaluation_time\n        self.solving_deadline = self.eval_deadline + config.solving_time\n        \n        # Best genome\n        self.best_genome: Optional[SolverGenome] = None\n    \n    def train(self) -> SolverGenome:\n        \"\"\"Training phase (5.5 hours)\"\"\"\n        self.logger.info(\"=\" * 80)\n        self.logger.info(\"ğŸ‹ï¸ TRAINING PHASE\")\n        self.logger.info(f\"â±ï¸  Duration: {self.config.training_time / 3600:.2f} hours\")\n        self.logger.info(\"=\" * 80)\n        \n        # Load training tasks\n        train_tasks = load_training_tasks(self.config.data_dir)\n        self.logger.info(f\"ğŸ“š Loaded {len(train_tasks)} training tasks\")\n        \n        # Initialize evolution\n        evolution = EvolutionEngine(self.config, self.logger, self.memory, self.knowledge_repo)\n        evolution.initialize_population(self.config.population_size)\n        \n        generation = 0\n        last_progress = time.time()\n        \n        # Evolution loop\n        while time.time() < self.training_deadline:\n            gen_start = time.time()\n            \n            best_fitness = evolution.evolve_generation(train_tasks)\n            \n            generation += 1\n            gen_time = time.time() - gen_start\n            \n            self.metrics.record_fitness(best_fitness, generation, str(id(evolution.best_genome)))\n            \n            # Progress updates every 5 minutes\n            if time.time() - last_progress >= self.config.progress_interval:\n                elapsed = (time.time() - self.start_time) / 3600\n                remaining = (self.training_deadline - time.time()) / 3600\n                self.logger.info(f\"ğŸ“ˆ Gen {generation} | Fitness: {best_fitness:.4f} | \"\n                               f\"Elapsed: {elapsed:.2f}h | Remaining: {remaining:.2f}h\")\n                last_progress = time.time()\n            \n            # Checkpoints every 10 generations\n            if generation % self.config.checkpoint_interval == 0:\n                checkpoint_path = self.config.output_dir / f'checkpoint_gen{generation}.json'\n                with open(checkpoint_path, 'w') as f:\n                    json.dump({\n                        'generation': generation,\n                        'best_fitness': best_fitness,\n                        'best_genome': evolution.best_genome.to_dict() if evolution.best_genome else None,\n                        'metrics': self.metrics.get_stats()\n                    }, f, indent=2)\n                self.logger.info(f\"ğŸ’¾ Checkpoint saved: {checkpoint_path}\")\n        \n        self.best_genome = evolution.best_genome\n        self.logger.info(f\"âœ… Training complete: {generation} generations, best fitness: {best_fitness:.4f}\")\n        \n        return self.best_genome\n    \n    def evaluate(self, best_genome: SolverGenome) -> float:\n        \"\"\"Evaluation phase (0.75 hours)\"\"\"\n        self.logger.info(\"=\" * 80)\n        self.logger.info(\"ğŸ” EVALUATION PHASE\")\n        self.logger.info(f\"â±ï¸  Duration: {self.config.evaluation_time / 3600:.2f} hours\")\n        self.logger.info(\"=\" * 80)\n        \n        # Load held-out training tasks\n        all_train_tasks = load_training_tasks(self.config.data_dir)\n        eval_tasks = random.sample(all_train_tasks, min(100, len(all_train_tasks)))\n        \n        self.logger.info(f\"ğŸ“Š Evaluating on {len(eval_tasks)} held-out tasks\")\n        \n        solver = BeamSearchSolver(self.config, self.logger, best_genome)\n        \n        correct = 0\n        total = 0\n        \n        for task in eval_tasks:\n            if time.time() >= self.eval_deadline:\n                break\n            \n            try:\n                score = solver._evaluate_program(best_genome.program, task)\n                correct += score\n                total += 1\n            except:\n                total += 1\n        \n        accuracy = correct / max(1, total)\n        self.logger.info(f\"âœ… Evaluation accuracy: {accuracy:.4f}\")\n        \n        return accuracy\n    \n    def solve(self, test_tasks: List[Dict], best_genome: SolverGenome) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Solving phase (1.5 hours)\"\"\"\n        self.logger.info(\"=\" * 80)\n        self.logger.info(\"ğŸ¯ SOLVING PHASE\")\n        self.logger.info(f\"â±ï¸  Duration: {self.config.solving_time / 3600:.2f} hours\")\n        self.logger.info(\"=\" * 80)\n        \n        self.logger.info(f\"ğŸ§ª Solving {len(test_tasks)} test tasks\")\n        \n        solver = BeamSearchSolver(self.config, self.logger, best_genome)\n        \n        solutions = {}\n        \n        for i, task in enumerate(test_tasks):\n            if time.time() >= self.solving_deadline:\n                self.logger.warning(f\"â° Time limit reached at task {i}/{len(test_tasks)}\")\n                break\n            \n            # Dynamic timeout\n            remaining = self.solving_deadline - time.time()\n            remaining_tasks = len(test_tasks) - i\n            task_timeout = min(self.config.task_timeout, remaining / max(1, remaining_tasks))\n            \n            try:\n                predictions = solver.solve_task(task, timeout=task_timeout)\n                solutions[task['id']] = predictions\n                self.metrics.tasks_solved += 1\n            except Exception as e:\n                self.logger.error(f\"âŒ Task {task['id']} failed: {e}\")\n                # Fallback: return test inputs as outputs\n                solutions[task['id']] = [np.array(tc['input']) for tc in task.get('test', [])]\n            \n            self.metrics.tasks_attempted += 1\n            \n            if (i + 1) % 10 == 0:\n                elapsed = (time.time() - (self.eval_deadline)) / 3600\n                self.logger.info(f\"â³ Progress: {i+1}/{len(test_tasks)} tasks | \"\n                               f\"Solved: {self.metrics.tasks_solved} | \"\n                               f\"Elapsed: {elapsed:.2f}h\")\n        \n        solve_rate = self.metrics.tasks_solved / max(1, self.metrics.tasks_attempted)\n        self.logger.info(f\"âœ… Solving complete: {self.metrics.tasks_solved}/{self.metrics.tasks_attempted} \"\n                        f\"({solve_rate:.2%})\")\n        \n        return solutions\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# DATA LOADING & SUBMISSION\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\ndef load_training_tasks(data_dir: Path) -> List[Dict]:\n    \"\"\"Load ARC training tasks from JSON\"\"\"\n    path = data_dir / 'arc-agi_training_challenges.json'\n    \n    if not path.exists():\n        logging.warning(f\"Training data not found: {path}\")\n        return []\n    \n    with open(path, 'r') as f:\n        data = json.load(f)\n    \n    tasks = [\n        {'id': tid, 'train': tdata['train'], 'test': tdata.get('test', [])}\n        for tid, tdata in data.items()\n    ]\n    \n    logging.info(f\"ğŸ“¥ Loaded {len(tasks)} training tasks\")\n    return tasks\n\n\ndef load_test_tasks(data_dir: Path) -> List[Dict]:\n    \"\"\"Load ARC test tasks from JSON\"\"\"\n    path = data_dir / 'arc-agi_test_challenges.json'\n    \n    if not path.exists():\n        logging.warning(f\"Test data not found: {path}\")\n        return []\n    \n    with open(path, 'r') as f:\n        data = json.load(f)\n    \n    tasks = [\n        {'id': tid, 'train': tdata.get('train', []), 'test': tdata['test']}\n        for tid, tdata in data.items()\n    ]\n    \n    logging.info(f\"ğŸ“¥ Loaded {len(tasks)} test tasks\")\n    return tasks\n\n\ndef save_submission(solutions: Dict[str, List[np.ndarray]], output_dir: Path):\n    \"\"\"Generate Kaggle submission JSON\"\"\"\n    submission = {}\n    \n    for task_id, predictions in solutions.items():\n        submission[task_id] = []\n        \n        for pred in predictions:\n            # Two attempts (same prediction for simplicity)\n            submission[task_id].append({\n                'attempt_1': pred.tolist(),\n                'attempt_2': pred.tolist()\n            })\n    \n    path = output_dir / 'submission.json'\n    with open(path, 'w') as f:\n        json.dump(submission, f, indent=2)\n    \n    logging.info(f\"ğŸ’¾ Submission saved: {path} ({len(submission)} tasks)\")\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# MAIN ENTRY POINT\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\ndef main():\n    \"\"\"One-click execution entry point\"\"\"\n    parser = argparse.ArgumentParser(\n        description='WakingOrca v6 - 7.75hr Championship AGI for ARC Prize 2025',\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    \n    parser.add_argument(\n        '--mode',\n        choices=['full', 'train', 'eval', 'solve'],\n        default='full',\n        help='Execution mode (default: full)'\n    )\n    \n    parser.add_argument(\n        '--data-dir',\n        type=Path,\n        default=Path('/kaggle/input/arc-prize-2025'),\n        help='Data directory path'\n    )\n    \n    parser.add_argument(\n        '--output-dir',\n        type=Path,\n        default=Path('/kaggle/working'),\n        help='Output directory path'\n    )\n    \n    parser.add_argument(\n        '--time-budget',\n        type=float,\n        default=7.75,\n        help='Total time budget in hours'\n    )\n    \n    args = parser.parse_args()\n    \n    # Initialize configuration\n    config = Config(\n        time_budget_hours=args.time_budget,\n        data_dir=args.data_dir,\n        output_dir=args.output_dir\n    )\n    \n    # Setup logging\n    logger = setup_logging(config)\n    \n    # Initialize orchestrator\n    orchestrator = WakingOrcaOrchestrator(config)\n    \n    try:\n        best_genome = None\n        \n        # Training phase\n        if args.mode in ['full', 'train']:\n            best_genome = orchestrator.train()\n        \n        # Evaluation phase\n        if args.mode in ['full', 'eval']:\n            if best_genome is None:\n                logger.error(\"No best genome available for evaluation\")\n                return 1\n            \n            eval_accuracy = orchestrator.evaluate(best_genome)\n            logger.info(f\"ğŸ“Š Evaluation accuracy: {eval_accuracy:.4f}\")\n        \n        # Solving phase\n        if args.mode in ['full', 'solve']:\n            if best_genome is None:\n                logger.error(\"No best genome available for solving\")\n                return 1\n            \n            test_tasks = load_test_tasks(config.data_dir)\n            \n            if not test_tasks:\n                logger.warning(\"No test tasks found\")\n                return 1\n            \n            solutions = orchestrator.solve(test_tasks, best_genome)\n            save_submission(solutions, config.output_dir)\n        \n        # Save metrics\n        metrics_path = config.output_dir / 'metrics.json'\n        orchestrator.metrics.save_metrics(metrics_path)\n        \n        logger.info(\"=\" * 80)\n        logger.info(\"ğŸ‹ WAKINGORCA V6 COMPLETE\")\n        logger.info(\"=\" * 80)\n        \n        # Final statistics\n        stats = orchestrator.metrics.get_stats()\n        logger.info(f\"ğŸ“ˆ Final Stats:\")\n        logger.info(f\"   Best Fitness: {stats['best_fitness']:.4f}\")\n        logger.info(f\"   Generations: {stats['generations']}\")\n        logger.info(f\"   Tasks Solved: {stats['tasks_solved']}/{stats['tasks_attempted']}\")\n        logger.info(f\"   Solve Rate: {stats['solve_rate']:.2%}\")\n        logger.info(f\"   RRBR Multiplier: {stats['gain_multiplier']:.3f}x\")\n        logger.info(f\"   Git Commits: {stats['commits']}\")\n        \n        return 0\n    \n    except Exception as e:\n        logger.error(f\"ğŸ’¥ Fatal error: {e}\", exc_info=True)\n        return 1\n\n\nif __name__ == '__main__':\n    sys.exit(main())","metadata":{"_uuid":"37848a86-b550-4d71-8fdd-d12f714cef1d","_cell_guid":"cb48424c-743d-4b3e-bc2e-e45a226796cb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}